# Copy to .env and set your keys. At least one LLM provider is required for /generate.

OPENAI_API_KEY=
GROQ_API_KEY=
GEMINI_API_KEY=
OLLAMA_BASE_URL=http://localhost:11434
# Free tier: use 60 to reduce 502/timeouts (Gemini/OpenAI rate limits).
REQUEST_TIMEOUT=60

# Gemini: use model gemini-1.5-flash or gemini-1.5-pro. Key from https://aistudio.google.com/apikey
